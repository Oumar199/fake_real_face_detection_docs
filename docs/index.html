<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Fake and real face detection with ViT &mdash; Fake and Real Face Detection with ViT 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            Fake and Real Face Detection with ViT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/context_of_the_project.html">Real and Fake Face Detection (RFFD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/bayesian_optimization.html">Bayesian Optimization from Scratch ğŸ”</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/generate_and_visualize.html">Generation and Exploration of the Images ğŸ”</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/preprocessing_and_loading.html">Preprocessing and loading âš—ï¸</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/split_dataset.html">Split data ğŸ«§</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/vit_model.html">Vision Transformer Model + Configuration and Metrics ğŸ‘“</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/deploy_to_hugging_face.html">Deploy the ViT Model ğŸš€</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">Fake and Real Face Detection with ViT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Fake and real face detection with ViT</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="fake-and-real-face-detection-with-vit">
<h1>Fake and real face detection with ViT<a class="headerlink" href="#fake-and-real-face-detection-with-vit" title="Permalink to this heading">ïƒ</a></h1>
<section id="real-and-fake-face-detection-rffd">
<h2>Real and Fake Face Detection (RFFD)<a class="headerlink" href="#real-and-fake-face-detection-rffd" title="Permalink to this heading">ïƒ</a></h2>
<p style="text-align: justify">
In this project, we use Deep Neural Networks to identify which image is fake or real. The training will be done on a dataset that we got from Kaggle (check it here <a href="https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection?resource=download)">kaggle_real_fake_faces</a>) created by <i style="color:chocolate">Seonghyeon Nam, Seoung Wug Oh, et al.</i> They used expert knowledge to photoshop authentic images. The fake images range between easy, medium, or hard to recognize. The modifications are made on the eyes, nose, and mouth (which permit human beings to recognize others) or the whole face.
</p>
<p><img alt="fake_photoshop" src="https://github.com/minostauros/Real-and-Fake-Face-Detection/raw/master/filename_description.jpg" /></p>
<p><i style="color: lightgray">The above image was got from the kaggle description of the image and describe  a file.</i></p>
<p>The image above is described as a fake image file. The name of the file can be decomposed into three different parts separated by underscores:</p>
<ul class="simple">
<li><p>The first part indicates the quality of the Photoshop or the difficulty of recognizing that it is fake;</p></li>
<li><p>The second part indicates the identification number of the image;</p></li>
<li><p>The third and final part indicates the modified segment of the face in binary digits with the following signature -&gt; <i style="chocolate">[bit_left_eye, bit_right_eye, bit_nose, bit_mouth]</i>.</p></li>
</ul>
<p>The segment is modified if it is the positive bit (1). Otherwise, the segment is not modified.</p>
<p>For further info, check out <a class="reference internal" href="usage.html"><span class="doc">Usage</span></a>.
Read installation instructions in <a class="reference internal" href="usage.html#installation"><span class="std std-ref">Installation</span></a>.</p>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="usage.html#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/context_of_the_project.html">Real and Fake Face Detection (RFFD)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/context_of_the_project.html#Objective">Objective</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/context_of_the_project.html#Steps-ğŸ§¾">Steps ğŸ§¾</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/bayesian_optimization.html">Bayesian Optimization from Scratch ğŸ”</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/bayesian_optimization.html#Objective-function">Objective function</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/bayesian_optimization.html#The-surrogate-function">The surrogate function</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/bayesian_optimization.html#Acquisition-Function">Acquisition Function</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/generate_and_visualize.html">Generation and Exploration of the Images ğŸ”</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Recuperate-the-images">Recuperate the images</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Number-of-recuperated-images">Number of recuperated images</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Visualize-a-grid-of-images">Visualize a grid of images</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Investigate-the-shapes">Investigate the shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Augmentation-methods-to-use">Augmentation methods to use</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/generate_and_visualize.html#Mean-and-variance-of-the-images">Mean and variance of the images</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/preprocessing_and_loading.html">Preprocessing and loading âš—ï¸</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/preprocessing_and_loading.html#Preprocessing">Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/preprocessing_and_loading.html#Custom-dataset">Custom dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/preprocessing_and_loading.html#Loss-function">Loss function</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/split_dataset.html">Split data ğŸ«§</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/vit_model.html">Vision Transformer Model + Configuration and Metrics ğŸ‘“</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/vit_model.html#Architecture">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/vit_model.html#Attention">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/vit_model.html#Metrics-and-predictions">Metrics and predictions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/deploy_to_hugging_face.html">Deploy the ViT Model ğŸš€</a></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage.html" class="btn btn-neutral float-right" title="Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Oumar Kane.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>