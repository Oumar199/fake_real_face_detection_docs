<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../genindex.html" /><link rel="search" title="Search" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../search.html" />

    <!-- Generated with Sphinx 6.2.1 and Furo 2023.05.20 -->
        <title>Real and Fake Face Detection (RFFD) - Fake and real face detection with ViT 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/styles/furo.css?digest=e6660623a769aa55fea372102b9bf3151b292993" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../index.html"><div class="brand">Fake and real face detection with ViT 0.0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../index.html">
  
  
  <span class="sidebar-brand-text">Fake and real face detection with ViT 0.0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../notebooks/context_of_the_project.html">Real and Fake Face Detection (RFFD)</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="Real-and-Fake-Face-Detection-(RFFD)">
<h1>Real and Fake Face Detection (RFFD)<a class="headerlink" href="#Real-and-Fake-Face-Detection-(RFFD)" title="Permalink to this heading">#</a></h1>
<p style="text-align: justify"><p>In this project, we use Deep Neural Networks to identify which image is fake or real. The training will be done on a dataset that we got from Kaggle (check it here kaggle_real_fake_faces) created by Seonghyeon Nam, Seoung Wug Oh, et al. They used expert knowledge to photoshop authentic images. The fake images range between easy, medium, or hard to recognize. The modifications are made on the eyes, nose, and mouth (which permit human beings to recognize others) or the whole face.</p>
</p><img alt="fake_photoshop" src="https://github.com/minostauros/Real-and-Fake-Face-Detection/raw/master/filename_description.jpg" />
<p>The above image was got from the kaggle description of the image and describe a file.</p>
<p>The image above is described as a fake image file. The name of the file can be decomposed into three different parts separated by underscores:</p>
<ul class="simple">
<li><p>The first part indicates the quality of the Photoshop or the difficulty of recognizing that it is fake;</p></li>
<li><p>The second part indicates the identification number of the image;</p></li>
<li><p>The third and final part indicates the modified segment of the face in binary digits with the following signature -&gt;</p></li>
</ul>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span>[bit_left_eye, bit_right_eye, bit_nose, bit_mouth]
</pre></div>
</div>
<p>The segment is modified if it is the positive bit (1). Otherwise, the segment is not modified.</p>
<p>Let us define bellow, with more details, our main objective.</p>
<section id="Objective">
<h2>Objective<a class="headerlink" href="#Objective" title="Permalink to this heading">#</a></h2>
<p>The purpose of the project is to use <code class="docutils literal notranslate"><span class="pre">Vision</span> <span class="pre">Transformer</span> <span class="pre">(ViT)</span></code> mixed with <code class="docutils literal notranslate"><span class="pre">Transfer</span> <span class="pre">Learning</span></code> to achieve a great accuracy and recall on the validation set. ViT is a new field which try to reproduce the same performance that the Convolution Neural Networks on image classification task but using the Transformer architecture. It can provide very accurate results.</p>
<img alt="VISION_TRANSFORMER" src="https://ghost.graviti.com/content/images/size/w1000/2022/02/image-1.png" />
<p>However, we cannot obtain such great result with only few images. ViT require around 14 millions images to learn on image classification task and we want to train the model only on one GPU device. Then the solution is to use Transfer Learning with a pre-trained Transformer to improve the overall performance.</p>
<p>We will fine-tune the pre-trained ViT Model for which the ArXiv paper is available at the following link <a class="reference external" href="https://arxiv.org/pdf/1908.03557.pdf">VisualBert</a>. It was pre-trained on the ImageNet-21k which contains 14 millions of images distributed over 21 thousand classes. The model is available in HuggingFace and can be import with the HuggingFace API.</p>
<p>For the moment, we want to obtain the following scores on the validation set:</p>
<ul class="simple">
<li><p><strong>Accuracy &gt; 80</strong></p></li>
<li><p><strong>f1 &gt; 80</strong></p></li>
</ul>
<p>Since it is related to medical predictions but only on social network security managing we will enforce ourself to obtain not search for more than 90% of <strong>Accuracy</strong> and <strong>f1-score</strong>.</p>
<p>The next section describe the steps that are required to achieve the project.</p>
</section>
<section id="Steps-🧾">
<h2>Steps 🧾<a class="headerlink" href="#Steps-🧾" title="Permalink to this heading">#</a></h2>
<p>Let us define bellow the main parts of our project:</p>
<ul class="simple">
<li><p>Data generation and exploration: We must recuperate the images and visualize them and identify their statistics. Moreover we will identify the augmentation methods to add to the images ➡️ <a class="reference external" href="generate_and_visualize.ipynb">Generating_and_visualizing</a></p></li>
<li><p>Preprocessing method: We must after exploration define the preprocessing to add before training the model on them. ➡️ <a class="reference external" href="preprocessing_and_loading.ipynb">Preprocessing_and_loading</a></p></li>
<li><p>Split the images between train, validation and test sets. ➡️ <a class="reference external" href="split_dataset.ipynb">Data_splitting</a></p></li>
<li><p>Load the ViT Model, explain briefly the architecture and define the metrics to add. ➡️ <a class="reference external" href="vit_model.ipynb">VitModel_Metrics</a></p></li>
<li><p>Search for the best model with The Bayesian Optimization strategy.</p></li>
<li><p>Fine-tune the best model.</p></li>
<li><p>Evaluate the model on the test set.</p></li>
<li><p>Deploy the model to Hugging Face.</p></li>
</ul>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Oumar Kane
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Real and Fake Face Detection (RFFD)</a><ul>
<li><a class="reference internal" href="#Objective">Objective</a></li>
<li><a class="reference internal" href="#Steps-🧾">Steps 🧾</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../" id="documentation_options" src="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/doctools.js"></script>
    <script src="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../../../../../../../../../../../../../../../../../../../../../../../../../../_static/scripts/furo.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>