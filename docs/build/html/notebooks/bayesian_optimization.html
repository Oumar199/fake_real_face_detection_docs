<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Bayesian Optimization from Scratch üîù &mdash; Fake and Real Face Detection with ViT 0.0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Generation and Exploration of the images üîé" href="generate_and_visualize.html" />
    <link rel="prev" title="Real and Fake Face Detection (RFFD)" href="context_of_the_project.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Fake and Real Face Detection with ViT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="context_of_the_project.html">Real and Fake Face Detection (RFFD)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Bayesian Optimization from Scratch üîù</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Objective-function">Objective function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#The-surrogate-function">The surrogate function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Acquisition-Function">Acquisition Function</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="generate_and_visualize.html">Generation and Exploration of the images üîé</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing_and_loading.html">Preprocessing and loading ‚öóÔ∏è</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_dataset.html">Split data ü´ß</a></li>
<li class="toctree-l1"><a class="reference internal" href="vit_model.html">Vision Transformer Model + Configuration and Metrics üëì</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_to_hugging_face.html">Deploy the ViT Model üöÄ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Fake and Real Face Detection with ViT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Bayesian Optimization from Scratch üîù</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/bayesian_optimization.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Bayesian-Optimization-from-Scratch-üîù">
<h1>Bayesian Optimization from Scratch üîù<a class="headerlink" href="#Bayesian-Optimization-from-Scratch-üîù" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>We must create some functions in this notebook that will help us make Bayesian Optimization to search for the best hyperparameter that will give the best model on the validation set. Bayesian Optimization uses Gaussian Process to approximate the objective function given input data. In our case, the input data is the set of hyperparameter values we must tune. The Bayesian theorem is used to direct the search to find the minimum or maximum of our objective function. The objective function can be
the <code class="docutils literal notranslate"><span class="pre">Accuracy,</span></code> the <code class="docutils literal notranslate"><span class="pre">Recall,</span></code> or whatever score function to evaluate the model performance.</p>
<p>The Bayesian Theorem suggests identifying a prior distribution for the objective function and updating it with the likelihood obtained with data given the objective function to get a posterior distribution. The Gaussian Process (GP) is commonly used for noisy distribution, which is difficult to directly simple from. The GP doesn‚Äôt need to optimize parameters to find the distribution and can give a standard derivation around the mean distribution, which defines the uncertainty about the
approximation.</p>
<p>The prior distribution is aMultivariate normal distribution with mean <span class="math notranslate nohighlight">\(m_0\)</span> and variance <span class="math notranslate nohighlight">\(K_{x, x}\)</span>, which is commonly a kernel distribution like the Radial Basis function (RBF) and calculates the similarity between the input values. Some noise <span class="math notranslate nohighlight">\(\epsilon\)</span> are added to the Prior Distribution with a mean of 0 and a variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. The posterior distribution is also Multivariate normal distribution for which we are searching the mean <span class="math notranslate nohighlight">\(m_y\)</span> vector and the
covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>. The <code class="docutils literal notranslate"><span class="pre">Cholesty</span> <span class="pre">iterative</span> <span class="pre">method</span></code> is commonly used to find the best posterior mean and covariance for a given new point. We will explain further the Gaussian Process.</p>
<p>For now, let us focus on Bayesian Optimization:</p>
<ul class="simple">
<li><p>After finding the posterior distribution, we can obtain the mean value of the objective function for any group of new hyperparameters. The new objective function values are used to find the best new samples for the subsequent evaluation trial since we make trials before finding the best hyperparameter values.</p></li>
<li><p>The first trial finds the first score from the objective function given random hyperparameter values.</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">surrogate</span> <span class="pre">function</span></code> is used to give that score from the Posterior Multivariate Distribution of the objective function given the input data.</p></li>
<li><p>The estimated score from the <code class="docutils literal notranslate"><span class="pre">surrogate</span> <span class="pre">function</span></code> is then used in a new function named <code class="docutils literal notranslate"><span class="pre">acquisition</span> <span class="pre">function</span></code> to generate new samples from the hyperparameter‚Äôs search spaces. It exists many different <code class="docutils literal notranslate"><span class="pre">acquisition</span> <span class="pre">functions.</span></code></p></li>
<li><p>The new samples are concatenated to the previous ones and used to train a further Posterior distribution.</p></li>
<li><p>The process is repeated until finding the most satisfying score.</p></li>
</ul>
<p><strong>Note</strong>: This idea is related to reinforcement learning methods to search for the following action(s) which maximize the value function (the reward of long term). We can consider the value function to be the cumulative distribution function of the approximate Posterior Multivariate Distribution function over the new samples and the new actions to be the ones sampled from the value function plus a variance rate to explore more states. The states are abstracted (not visible) in our case.</p>
<p>We will implement the Bayesian Optimization process from scratch since we want to customize it for the current project. We will not code the Gaussian Process Regression sub-process since it is already integrated into the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library. We can also use the <code class="docutils literal notranslate"><span class="pre">GPytorch</span></code> library which can provide better result but for the purpose of that project we will not need it. Let us define nextly the objective function.</p>
<p>Let us import the necessary libraries.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">MSELoss</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
<section id="Objective-function">
<h2>Objective function<a class="headerlink" href="#Objective-function" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">MSELoss</span></code> to calculate the value returned by the objective function, which is our training function. It will calculate the mean squared error between values predicted from a feed-forward neural network and pre-defined target values. The input and target values are randomly initialized from a Gaussian distribution. We will need input data of 8 variables and 100 samples (not very large, not fast up the training). The following parameters will be necessary for a sample example:</p>
<ul class="simple">
<li><p>The number of epochs -&gt; ‚Ä¶ [1, 10]</p></li>
<li><p>The number of layers -&gt; ‚Ä¶ [1, 4]</p></li>
<li><p>The number of features -&gt; ‚Ä¶ [40, 100]</p></li>
<li><p>The learning rate -&gt; ‚Ä¶ [1e-1, 1e-4]</p></li>
</ul>
<p>Let us initialize the input data and the targets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Let us initialize the model and the objective function. Notice that we must add the noise we defined earlier to the final calculated score. The noise is sampled from a normal distribution with a mean of 0 and a scale that we must determine. Let us choose a <span class="math notranslate nohighlight">\(\sigma^2 = 0.1\)</span> scale as the default.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model</span>
<span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())]</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)])</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

    <span class="n">sequence</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sequence</span>

<span class="c1"># Only one iteration will be sufficient</span>
<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>

    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">set_model</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_features&#39;</span><span class="p">],</span> <span class="n">n_layers</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_layers&#39;</span><span class="p">])</span>

    <span class="n">optimizer_</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer_</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">optimizer_</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span>
</pre></div>
</div>
</div>
<p>We must also define simple functions which generate random samples from search spaces.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> fake-face-detection/fake_face_detection/utils/sampling.py
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">get_random_sample</span><span class="p">(</span><span class="n">search_space</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Recuperate a random sample</span>

<span class="sd">    Args:</span>
<span class="sd">        search_space (dict): A dictionary defining the search space</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: &#39;min&#39; and &#39;max&#39; can only be numbers</span>
<span class="sd">        KeyError: Only the following keys can be provided {&#39;min&#39;, &#39;max&#39;}, {&#39;value&#39;}, {&#39;values&#39;} or {&#39;values&#39;, &#39;p&#39;}</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[int, float, str]: The random sample</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">search_space</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">keys</span> <span class="o">==</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]):</span>

        <span class="k">assert</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>

            <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">])</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>

            <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You can only provide int or float values with min max!&quot;</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">keys</span> <span class="o">==</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;value&#39;</span><span class="p">]):</span>

        <span class="k">return</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>

    <span class="k">elif</span> <span class="n">keys</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="s1">&#39;values&#39;</span><span class="p">])):</span>

        <span class="n">p</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s1">&#39;p&#39;</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span> <span class="n">p</span> <span class="o">=</span> <span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">search_space</span><span class="p">[</span><span class="s1">&#39;values&#39;</span><span class="p">],</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>

        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;You didn&#39;t provide right keys! Try between: {&#39;min&#39;, &#39;max&#39;}, {&#39;value&#39;}, {&#39;values&#39;} or {&#39;values&#39;, &#39;p&#39;}&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_random_samples</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Recuperate random samples from a dictionary of search spaces</span>

<span class="sd">    Args:</span>
<span class="sd">        search_spaces (dict): A dictionary where the keys are the hyperparameter names and the values are the search spaces</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary where the keys are the hyperparameter names and the values are the sampled values from the search spaces</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">search_space</span> <span class="ow">in</span> <span class="n">search_spaces</span><span class="p">:</span>

        <span class="n">samples</span><span class="p">[</span><span class="n">search_space</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_random_sample</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">[</span><span class="n">search_space</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting fake-face-detection/fake_face_detection/utils/sampling.py
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> fake-face-detection/fake_face_detection/utils/sampling.py
</pre></div>
</div>
</div>
<p>Let us test the sampling functions and do training to obtain a first value.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the search spaces</span>
<span class="n">search_spaces</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mi">10</span>
    <span class="p">},</span>
    <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;values&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="s1">&#39;n_features&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="mi">50</span>
    <span class="p">},</span>
    <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mf">1e-1</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># recuperate random samples</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">get_random_samples</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We obtain the following samples for each hyperparameter.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;epochs&#39;: 7, &#39;n_layers&#39;: 4, &#39;n_features&#39;: 50, &#39;lr&#39;: 0.02310174766808769}
</pre></div></div>
</div>
<p>Let us train the model with them and recuperate the loss.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We obtain the following loss from the sampled hyperparameter values.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
5.45991277150153
</pre></div></div>
</div>
<p>Let us now implement the surrogate function</p>
</section>
<section id="The-surrogate-function">
<h2>The surrogate function<a class="headerlink" href="#The-surrogate-function" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>The surrogate tries to estimate the objective function using the Bayes theorem probabilistically. We want to find the probability of obtaining such a score <span class="math notranslate nohighlight">\(f\)</span> conditionally to input data <span class="math notranslate nohighlight">\(D\)</span>. The score is the loss calculated after training, and the input data is the set of parameters. To simulate the posterior distribution <span class="math notranslate nohighlight">\(P(f/D)\)</span>, we decided to use the Gaussian Process (GP) Regression. The kernel used to calculate the similarity between the input data sample can be the
<code class="docutils literal notranslate"><span class="pre">Radial</span> <span class="pre">Basis</span> <span class="pre">Function</span></code> kernel which commonly provides excellent results. The GP Regression is already implemented in sklearn. We can use it directly for our implementation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the distribution</span>
<span class="n">gp_model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The only data we have is the sample hyperparameter value which instantiates the input data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate the input data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">())]</span>
</pre></div>
</div>
</div>
<p>And the only score we currently have is the loss we calculated earlier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate the scores</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[[</span><span class="n">loss</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<p>Let us fit the model with the data and scores.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gp_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "‚ñ∏";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "‚ñæ";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GaussianProcessRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianProcessRegressor</label><div class="sk-toggleable__content"><pre>GaussianProcessRegressor()</pre></div></div></div></div></div></div>
</div>
<p>We can estimate the value of the target using the input data (and the standard deviation).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span><span class="p">,</span> <span class="n">stds</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We obtain the following prediction, which is very close to the actual loss.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span><span class="p">,</span> <span class="n">stds</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([5.45991277]), array([1.00000004e-05]))
</pre></div></div>
</div>
<p>It is time to choose an acquisition function to generate new samples.</p>
</section>
<section id="Acquisition-Function">
<h2>Acquisition Function<a class="headerlink" href="#Acquisition-Function" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>The acquisition function will use the surrogate to examine which of many random samples is the best suited for the next generation:</p>
<ol class="arabic">
<li><p>First, we need to generate random samples from the search spaces.</p></li>
<li><p>Second, since we already have an approximation of the objective function‚Äôs distribution conditionally to a input data via the surrogate function we can estimate the vector mean and their corresponding standard deviations:</p>
<div class="math notranslate nohighlight">
\[\mu_e, \sigma_e \sim P(f/samples)\]</div>
<p>(where <span class="math notranslate nohighlight">\(b\)</span> is the number random samples) and $estimated_stds obtained from the samples generated at 1 and the corresponding standard deviations.</p>
</li>
<li><p>Third, the values in the vector of the estimated means, , are compared to the best mean:</p>
<div class="math notranslate nohighlight">
\[\max(\mu), \space where \space \mu,. \sim P(f/input\_data)\]</div>
<p>Calculated from the previous best input data calculating the probability of improvement which is the cumulative normal distribution of the normalized distance between the means (or the regret as in RL):</p>
</li>
</ol>
<div class="math notranslate nohighlight">
\[PI = P(f &lt; \frac{\mu_e - \mu_{best}}{\sigma_e + \epsilon})\]</div>
<p>Where <span class="math notranslate nohighlight">\(\epsilon\)</span> is added to avoid division by zero.</p>
<p><strong>Remark</strong>: it exists different acquisition functions like the UCB function. But for the purpose of our project we will focus on the probability of improvement.</p>
<p><strong>Note</strong>: In our example we want to minimize the loss so we must take <span class="math notranslate nohighlight">\(-\mu_e\)</span> and <span class="math notranslate nohighlight">\(-\mu\)</span> to find the best solution.</p>
<p>Let us implement bellow the acquisition function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> fake-face-detection/fake_face_detection/utils/acquisitions.py
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">PI_acquisition</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">X_prime</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">GaussianProcessRegressor</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Acquisition function for bayesian optimization using probability of improvement</span>

<span class="sd">    Args:</span>
<span class="sd">        X (List): A list containing the input data</span>
<span class="sd">        X_prime (List): A list containing the generate samples</span>
<span class="sd">        model (GaussianProcessRegressor): The gaussian model to use</span>
<span class="sd">        maximize (bool, optional): A boolean value indicating the optimization objective. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List: A list containing the probabilities</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># let us predict the means for the input data</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># let us calculate the means and standard deviation for the random samples</span>
    <span class="n">mu_e</span><span class="p">,</span> <span class="n">std_e</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prime</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">maximize</span><span class="p">:</span>

        <span class="n">mu</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu</span>

        <span class="n">mu_e</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu_e</span>

    <span class="c1"># let us take the best mean</span>
    <span class="n">mu_best</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

    <span class="c1"># let us calculate the probability of improvement</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">((</span><span class="n">mu_e</span> <span class="o">-</span> <span class="n">mu_best</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">probs</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting fake-face-detection/fake_face_detection/utils/acquisitions.py
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> fake-face-detection/fake_face_detection/utils/acquisitions.py
</pre></div>
</div>
</div>
<p>The next generated sample is the one which have the best probability of being chosen.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> fake-face-detection/fake_face_detection/utils/generation.py
<span class="kn">from</span> <span class="nn">fake_face_detection.utils.acquisitions</span> <span class="kn">import</span> <span class="n">PI_acquisition</span>
<span class="kn">from</span> <span class="nn">fake_face_detection.utils.sampling</span> <span class="kn">import</span> <span class="n">get_random_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">PI_generate_sample</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">GaussianProcessRegressor</span><span class="p">,</span> <span class="n">search_spaces</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">n_tests</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate new samples with the probability of improvement</span>

<span class="sd">    Args:</span>
<span class="sd">        X (Iterable): The list of input data</span>
<span class="sd">        model (GaussianProcessRegressor): The model to train</span>
<span class="sd">        search_spaces (dict): The search spaces</span>
<span class="sd">        n_tests (int, optional): The number of random samples to test. Defaults to 100.</span>
<span class="sd">        maximize (bool, optional): The optimization strategy. If maximize == True -&gt; maximize, else -&gt; minimize. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List: The new sample</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># let us create random samples</span>
    <span class="n">X_prime</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">get_random_samples</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_tests</span><span class="p">)]</span>

    <span class="c1"># let us recuperate the probabilities from the acquisition function</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">PI_acquisition</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_prime</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">maximize</span> <span class="o">=</span> <span class="n">maximize</span><span class="p">)</span>

    <span class="c1"># let us return the best sample</span>
    <span class="k">return</span> <span class="n">X_prime</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting fake-face-detection/fake_face_detection/utils/generation.py
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> fake-face-detection/fake_face_detection/utils/generation.py
</pre></div>
</div>
</div>
<p>Let us generate the next sample with the above function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_samples</span> <span class="o">=</span> <span class="n">PI_generate_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">gp_model</span><span class="p">,</span> <span class="n">search_spaces</span><span class="p">,</span> <span class="n">maximize</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We obtained the following new values for the next training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_samples</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[1, 1, 50, 0.03131119507929577]
</pre></div></div>
</div>
<p>Let us train again the model and recuperate the new score.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize the new dictionary of samples</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">new_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">)}</span>

<span class="c1"># calculate the new score</span>
<span class="n">new_score</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_score</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.981966343907849
</pre></div></div>
</div>
<p>We don‚Äôt have enough data so we can obtain a worth loss. We must concatenate the generated samples and scores in order to obtain a more accurate prediction from the surrogate function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)</span>
<span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">new_score</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> fake-face-detection/fake_face_detection/optimization/bayesian_optimization.py
<span class="kn">from</span> <span class="nn">fake_face_detection.utils.generation</span> <span class="kn">import</span> <span class="n">PI_generate_sample</span> <span class="k">as</span> <span class="n">generate_sample</span>
<span class="kn">from</span> <span class="nn">fake_face_detection.utils.acquisitions</span> <span class="kn">import</span> <span class="n">PI_acquisition</span> <span class="k">as</span> <span class="n">acquisition</span>
<span class="kn">from</span> <span class="nn">fake_face_detection.utils.sampling</span> <span class="kn">import</span> <span class="n">get_random_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">SimpleBayesianOptimization</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objective</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">search_spaces</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>

        <span class="c1"># recuperate the optimization strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="o">=</span> <span class="n">maximize</span>

        <span class="c1"># recuperate random sample</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">get_random_samples</span><span class="p">(</span><span class="n">search_spaces</span><span class="p">)</span>

        <span class="c1"># initialize the search spaces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">search_spaces</span> <span class="o">=</span> <span class="n">search_spaces</span>

        <span class="c1"># initialize the objective function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>

        <span class="c1"># calculate the first score</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="c1"># initialize the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">()</span>

        <span class="c1"># initialize the input data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">values</span><span class="p">())]</span>

        <span class="c1"># initialize the scores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">=</span> <span class="p">[[</span><span class="n">score</span><span class="p">]]</span>

        <span class="c1"># fit the model with the input data and the target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n_tests</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finding the best hyperparameters with the Bayesian Optimization</span>

<span class="sd">        Args:</span>
<span class="sd">            n_trials (int, optional): The number of trials. Defaults to 50.</span>
<span class="sd">            n_tests (int, optional): The number of random samples to test for each trial. Defaults to 100.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># let us make multiple trials in order to find the best params</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trials</span><span class="p">):</span>

            <span class="c1"># let us generate new samples with the acquisition and the surrogate functions</span>
            <span class="n">new_sample</span> <span class="o">=</span> <span class="n">generate_sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">search_spaces</span><span class="p">,</span> <span class="n">n_tests</span><span class="p">,</span> <span class="n">maximize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">new_sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">search_spaces</span><span class="p">)}</span>

            <span class="c1"># let us recuperate a new score from the new sample</span>
            <span class="n">new_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

            <span class="c1"># let us add the new sample, target and score to their lists</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_sample</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">new_score</span><span class="p">])</span>

            <span class="c1"># let us train again the model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Recuperate the generated samples and the scores</span>

<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: A data frame containing the results</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># let us return the results as a data frame</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">object</span><span class="p">)[:,</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">search_spaces</span><span class="p">)}</span>

        <span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]})</span>

        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting fake-face-detection/fake_face_detection/optimization/bayesian_optimization.py
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> fake-face-detection/fake_face_detection/optimization/bayesian_optimization.py
</pre></div>
</div>
</div>
<p>Let us train recuperate the samples obtained after 50 trials.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize the attributes</span>
<span class="n">simple_bayesian_optimization</span> <span class="o">=</span> <span class="n">SimpleBayesianOptimization</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">search_spaces</span><span class="p">,</span> <span class="n">maximize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># optimize to find the best hyperparameters</span>
<span class="n">simple_bayesian_optimization</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># recuperate the results</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">simple_bayesian_optimization</span><span class="o">.</span><span class="n">get_results</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># display the results</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">results</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>n_layers</th>
      <th>n_features</th>
      <th>lr</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
      <td>1</td>
      <td>50</td>
      <td>0.047436</td>
      <td>6.404869</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>3</td>
      <td>50</td>
      <td>0.017284</td>
      <td>5.858079</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>4</td>
      <td>50</td>
      <td>0.014734</td>
      <td>6.854856</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>1</td>
      <td>50</td>
      <td>0.033547</td>
      <td>5.269045</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>50</td>
      <td>0.055477</td>
      <td>2.092933</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10</td>
      <td>4</td>
      <td>50</td>
      <td>0.09402</td>
      <td>-0.105739</td>
    </tr>
    <tr>
      <th>6</th>
      <td>10</td>
      <td>4</td>
      <td>50</td>
      <td>0.076977</td>
      <td>0.254223</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>4</td>
      <td>50</td>
      <td>0.059555</td>
      <td>2.381605</td>
    </tr>
    <tr>
      <th>8</th>
      <td>10</td>
      <td>3</td>
      <td>50</td>
      <td>0.095012</td>
      <td>0.248136</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>3</td>
      <td>50</td>
      <td>0.096846</td>
      <td>0.127560</td>
    </tr>
    <tr>
      <th>10</th>
      <td>9</td>
      <td>4</td>
      <td>50</td>
      <td>0.089688</td>
      <td>-0.078562</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3</td>
      <td>1</td>
      <td>50</td>
      <td>0.082321</td>
      <td>1.490068</td>
    </tr>
    <tr>
      <th>12</th>
      <td>9</td>
      <td>4</td>
      <td>50</td>
      <td>0.094775</td>
      <td>-0.000623</td>
    </tr>
    <tr>
      <th>13</th>
      <td>9</td>
      <td>4</td>
      <td>50</td>
      <td>0.044421</td>
      <td>0.978622</td>
    </tr>
    <tr>
      <th>14</th>
      <td>5</td>
      <td>4</td>
      <td>50</td>
      <td>0.085948</td>
      <td>0.061297</td>
    </tr>
    <tr>
      <th>15</th>
      <td>9</td>
      <td>4</td>
      <td>50</td>
      <td>0.081952</td>
      <td>-0.012566</td>
    </tr>
    <tr>
      <th>16</th>
      <td>5</td>
      <td>3</td>
      <td>50</td>
      <td>0.042656</td>
      <td>1.983545</td>
    </tr>
    <tr>
      <th>17</th>
      <td>8</td>
      <td>2</td>
      <td>50</td>
      <td>0.053319</td>
      <td>0.799534</td>
    </tr>
    <tr>
      <th>18</th>
      <td>8</td>
      <td>1</td>
      <td>50</td>
      <td>0.004587</td>
      <td>4.902961</td>
    </tr>
    <tr>
      <th>19</th>
      <td>4</td>
      <td>1</td>
      <td>50</td>
      <td>0.021009</td>
      <td>7.128041</td>
    </tr>
    <tr>
      <th>20</th>
      <td>2</td>
      <td>1</td>
      <td>50</td>
      <td>0.079397</td>
      <td>0.987655</td>
    </tr>
    <tr>
      <th>21</th>
      <td>4</td>
      <td>4</td>
      <td>50</td>
      <td>0.088559</td>
      <td>-0.152193</td>
    </tr>
    <tr>
      <th>22</th>
      <td>4</td>
      <td>4</td>
      <td>50</td>
      <td>0.074723</td>
      <td>0.013811</td>
    </tr>
    <tr>
      <th>23</th>
      <td>8</td>
      <td>3</td>
      <td>50</td>
      <td>0.09264</td>
      <td>-0.224459</td>
    </tr>
    <tr>
      <th>24</th>
      <td>8</td>
      <td>3</td>
      <td>50</td>
      <td>0.08645</td>
      <td>0.280591</td>
    </tr>
    <tr>
      <th>25</th>
      <td>8</td>
      <td>2</td>
      <td>50</td>
      <td>0.080311</td>
      <td>0.240702</td>
    </tr>
    <tr>
      <th>26</th>
      <td>8</td>
      <td>3</td>
      <td>50</td>
      <td>0.09727</td>
      <td>-0.012525</td>
    </tr>
    <tr>
      <th>27</th>
      <td>6</td>
      <td>4</td>
      <td>50</td>
      <td>0.091157</td>
      <td>-0.001376</td>
    </tr>
    <tr>
      <th>28</th>
      <td>7</td>
      <td>4</td>
      <td>50</td>
      <td>0.099791</td>
      <td>0.012959</td>
    </tr>
    <tr>
      <th>29</th>
      <td>6</td>
      <td>4</td>
      <td>50</td>
      <td>0.042588</td>
      <td>0.999145</td>
    </tr>
    <tr>
      <th>30</th>
      <td>7</td>
      <td>4</td>
      <td>50</td>
      <td>0.079175</td>
      <td>0.087425</td>
    </tr>
    <tr>
      <th>31</th>
      <td>5</td>
      <td>4</td>
      <td>50</td>
      <td>0.09686</td>
      <td>0.184545</td>
    </tr>
    <tr>
      <th>32</th>
      <td>8</td>
      <td>2</td>
      <td>50</td>
      <td>0.071047</td>
      <td>0.731057</td>
    </tr>
    <tr>
      <th>33</th>
      <td>5</td>
      <td>4</td>
      <td>50</td>
      <td>0.040592</td>
      <td>2.449255</td>
    </tr>
    <tr>
      <th>34</th>
      <td>8</td>
      <td>2</td>
      <td>50</td>
      <td>0.013261</td>
      <td>8.836807</td>
    </tr>
    <tr>
      <th>35</th>
      <td>10</td>
      <td>4</td>
      <td>50</td>
      <td>0.048035</td>
      <td>1.844829</td>
    </tr>
    <tr>
      <th>36</th>
      <td>7</td>
      <td>3</td>
      <td>50</td>
      <td>0.085077</td>
      <td>0.236993</td>
    </tr>
    <tr>
      <th>37</th>
      <td>7</td>
      <td>2</td>
      <td>50</td>
      <td>0.066092</td>
      <td>0.690044</td>
    </tr>
    <tr>
      <th>38</th>
      <td>1</td>
      <td>2</td>
      <td>50</td>
      <td>0.063592</td>
      <td>1.830456</td>
    </tr>
    <tr>
      <th>39</th>
      <td>6</td>
      <td>3</td>
      <td>50</td>
      <td>0.09657</td>
      <td>0.017104</td>
    </tr>
    <tr>
      <th>40</th>
      <td>8</td>
      <td>4</td>
      <td>50</td>
      <td>0.095475</td>
      <td>-0.000947</td>
    </tr>
    <tr>
      <th>41</th>
      <td>3</td>
      <td>4</td>
      <td>50</td>
      <td>0.088609</td>
      <td>0.026383</td>
    </tr>
    <tr>
      <th>42</th>
      <td>9</td>
      <td>2</td>
      <td>50</td>
      <td>0.068641</td>
      <td>1.021106</td>
    </tr>
    <tr>
      <th>43</th>
      <td>1</td>
      <td>3</td>
      <td>50</td>
      <td>0.059763</td>
      <td>3.608931</td>
    </tr>
    <tr>
      <th>44</th>
      <td>2</td>
      <td>4</td>
      <td>50</td>
      <td>0.033989</td>
      <td>3.485960</td>
    </tr>
    <tr>
      <th>45</th>
      <td>4</td>
      <td>4</td>
      <td>50</td>
      <td>0.089095</td>
      <td>0.016238</td>
    </tr>
    <tr>
      <th>46</th>
      <td>2</td>
      <td>2</td>
      <td>50</td>
      <td>0.063018</td>
      <td>0.136449</td>
    </tr>
    <tr>
      <th>47</th>
      <td>3</td>
      <td>2</td>
      <td>50</td>
      <td>0.051632</td>
      <td>1.227410</td>
    </tr>
    <tr>
      <th>48</th>
      <td>4</td>
      <td>3</td>
      <td>50</td>
      <td>0.08359</td>
      <td>0.065483</td>
    </tr>
    <tr>
      <th>49</th>
      <td>6</td>
      <td>2</td>
      <td>50</td>
      <td>0.07365</td>
      <td>0.429036</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Let us print the best loss and the corresponding hyperparameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>n_layers</th>
      <th>n_features</th>
      <th>lr</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>23</th>
      <td>8</td>
      <td>3</td>
      <td>50</td>
      <td>0.09264</td>
      <td>-0.224459</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Let us get the loss with best parameters without adding a large noise.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># recuperate the parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()]</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;score&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s1">&#39;list&#39;</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># train and get the loss</span>
<span class="n">objective</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.06265220941131512
</pre></div></div>
</div>
<p>We highly progressed since the first random sample ‚úåÔ∏è.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="context_of_the_project.html" class="btn btn-neutral float-left" title="Real and Fake Face Detection (RFFD)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="generate_and_visualize.html" class="btn btn-neutral float-right" title="Generation and Exploration of the images üîé" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Oumar Kane.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>